<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Space-Time Anomaly Detection using Scan Statistics &bull; scanstatistics</title><!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous"><script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous"><!-- pkgdown --><link href="pkgdown.css" rel="stylesheet"><script src="jquery.sticky-kit.min.js"></script><script src="pkgdown.js"></script><!-- mathjax --><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">scanstatistics</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="reference/index.html">Reference</a>
</li>
<li>
  <a href="articles/index.html">Articles</a>
</li>
<li>
  <a href="news/index.html">News</a>
</li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="https://github.com/BenjaK/scanstatistics">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    

    
    
<div class="contents">
<!-- README.md is generated from README.Rmd. Please edit that file -->

<div id="scanstatistics" class="section level1">
<div class="page-header"><h1 class="hasAnchor"><a href="#scanstatistics" class="anchor"> </a>scanstatistics</h1></div>
<p>An R package for space-time anomaly detection using scan statistics.</p>
<div id="installing-the-package" class="section level2">
<h2 class="hasAnchor"><a href="#installing-the-package" class="anchor"> </a>Installing the package</h2>
<p>To install the latest (CRAN) release of this package, type the following:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">"scanstatistics"</span>)</code></pre></div>
<p>To install the development version of this package, type this instead:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">devtools::<span class="kw">install_github</span>(<span class="st">"benjak/scanstatistics"</span>)</code></pre></div>
</div>
<div id="what-are-scan-statistics" class="section level2">
<h2 class="hasAnchor"><a href="#what-are-scan-statistics" class="anchor"> </a>What are scan statistics?</h2>
<p>Scan statistics are used to detect anomalous clusters in spatial or space-time data. The gist of the methodology, at least in this package, is this:</p>
<ol style="list-style-type: decimal"><li>Monitor one or more data streams at multiple <em>locations</em> over intervals of time.</li>
<li>Form a set of space-time <em>clusters</em>, each consisting of (1) a collection of locations, and (2) an interval of time stretching from the present to some number of time periods in the past.</li>
<li>For each cluster, compute a statistic based on both the observed and the expected responses. Report the clusters with the largest statistics.</li>
</ol><p>My thesis, <a href="https://goo.gl/GdseSh">available online</a>, provides a deeper overview of scan statistics.</p>
</div>
<div id="main-functions" class="section level2">
<h2 class="hasAnchor"><a href="#main-functions" class="anchor"> </a>Main functions</h2>
<div id="scan-statistics" class="section level3">
<h3 class="hasAnchor"><a href="#scan-statistics" class="anchor"> </a>Scan statistics</h3>
<ul><li><strong><code>scan_poisson</code></strong>: computes a scan statistic for data following a Poisson distribution.</li>
<li><strong><code>scan_negbin</code></strong>: computes a scan statistic for data following a negative binomial distribution.</li>
<li><strong><code>scan_zip</code></strong>: computes a scan statistic for data following a zero-inflated Poisson distribution.</li>
</ul></div>
<div id="zone-creation" class="section level3">
<h3 class="hasAnchor"><a href="#zone-creation" class="anchor"> </a>Zone creation</h3>
<ul><li><strong><code>knn_zones</code></strong>: Creates a set of spatial <em>zones</em> (groups of locations) to scan for anomalies. Input is a matrix in which rows are the enumerated locations, and columns the <em>k</em> nearest neighbors. To create such a matrix, the following two functions are useful:
<ul><li><strong><code>coords_to_knn</code></strong>: use <code>stats::dist</code> to get the <em>k</em> nearest neighbors of each location into a format usable by <code>knn_zones</code>.</li>
<li><strong><code>dist_to_knn</code></strong>: use an already computed distance matrix to get the <em>k</em> nearest neighbors of each location into a format usable by <code>knn_zones</code>.</li>
</ul></li>
<li><strong><code>flexible_zones</code></strong>: An alternative to <code>knn_zones</code> that uses the adjacency structure of locations to create a richer set of zones. The additional input is an adjacency matrix, but otherwise works as <code>knn_zones</code>.</li>
</ul></div>
<div id="miscellaneous" class="section level3">
<h3 class="hasAnchor"><a href="#miscellaneous" class="anchor"> </a>Miscellaneous</h3>
<ul><li><strong><code>score_locations</code></strong>: Score each location by how likely it is to have an ongoing anomaly in it. This score is heuristically motivated, not theoretically so.</li>
<li><strong><code>top_clusters</code></strong>: Get the top <em>k</em> space-time clusters, either overlapping or non-overlapping in the spatial dimension.</li>
</ul></div>
</div>
<div id="example-brain-cancer-in-new-mexico" class="section level2">
<h2 class="hasAnchor"><a href="#example-brain-cancer-in-new-mexico" class="anchor"> </a>Example: Brain cancer in New Mexico</h2>
<p>To demonstrate the scan statistics in this package, we will use a dataset of the annual number of brain cancer cases in the counties of New Mexico, for the years 1973-1991. This data was studied by <span class="citation">Kulldorff et al. (1998)</span>, who detected a cluster of cancer cases in the counties Los Alamos and Santa Fe during the years 1986-1989, though the excess of brain cancer in this cluster was not deemed statistically significant. The data originally comes from the package <em>rsatscan</em> <span class="citation">(Kleinman 2015)</span>, which provides an interface to the program <a href="http://www.satscan.org">SaTScan&trade;</a>, but it has been aggregated and extended for the <em>scanstatistics</em> package.</p>
<p>To get familiar with the counties of New Mexico, we begin by plotting them on a map using the data table <code>NM_map</code> which comes with the <em>scanstatistics</em> package:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(scanstatistics)
<span class="co">#&gt; Loading required package: data.table</span>
<span class="co">#&gt; data.table 1.9.6  For help type ?data.table or https://github.com/Rdatatable/data.table/wiki</span>
<span class="co">#&gt; The fastest way to learn (by data.table authors): https://www.datacamp.com/courses/data-analysis-the-data-table-way</span>
<span class="kw">library</span>(ggplot2)

<span class="co"># Load map data</span>
<span class="kw">data</span>(NM_map)

<span class="co"># Place the county names at the centroid of the counties. The following function</span>
<span class="co"># calculates the geographical centroids from the polygons in NM_map.</span>
<span class="co"># See: https://en.wikipedia.org/wiki/Centroid#Centroid_of_polygon</span>
polygon_centroid &lt;-<span class="st"> </span>function(x0, y0) {
  x1 &lt;-<span class="st"> </span><span class="kw">c</span>(x0[-<span class="dv">1</span>], x0[<span class="dv">1</span>])
  y1 &lt;-<span class="st"> </span><span class="kw">c</span>(y0[-<span class="dv">1</span>], y0[<span class="dv">1</span>])
  A &lt;-<span class="st"> </span><span class="kw">sum</span>(x0 *<span class="st"> </span>y1 -<span class="st"> </span>x1 *<span class="st"> </span>y0) /<span class="st"> </span><span class="dv">2</span>
  Cx &lt;-<span class="st"> </span><span class="kw">sum</span>((x0 +<span class="st"> </span>x1) *<span class="st"> </span>(x0 *<span class="st"> </span>y1 -<span class="st"> </span>x1 *<span class="st"> </span>y0)) /<span class="st"> </span>(<span class="dv">6</span> *<span class="st"> </span>A)
  Cy &lt;-<span class="st"> </span><span class="kw">sum</span>((y0 +<span class="st"> </span>y1) *<span class="st"> </span>(x0 *<span class="st"> </span>y1 -<span class="st"> </span>x1 *<span class="st"> </span>y0)) /<span class="st"> </span>(<span class="dv">6</span> *<span class="st"> </span>A)
  <span class="kw">data.frame</span>(<span class="dt">long =</span> Cx, <span class="dt">lat =</span> Cy)
}

<span class="co"># Calculate geographic centroids for each county</span>
centroids &lt;-<span class="st"> </span>NM_map[, <span class="kw">polygon_centroid</span>(long, lat), by =<span class="st"> </span>.(subregion)]

<span class="co"># Plot map with labels at centroids</span>
<span class="kw">ggplot</span>() +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_polygon</span>(<span class="dt">data =</span> NM_map,
               <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> long, <span class="dt">y =</span> lat, <span class="dt">group =</span> group),
               <span class="dt">color =</span> <span class="st">"grey"</span>, <span class="dt">fill =</span> <span class="st">"white"</span>) +
<span class="st">  </span><span class="kw">geom_text</span>(<span class="dt">data =</span> centroids, 
            <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> long, <span class="dt">y =</span> lat, <span class="dt">label =</span> subregion)) +
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">"Counties of New Mexico"</span>)</code></pre></div>
<p><img src="README_figures/unnamed-chunk-2-1.png" width="960"></p>
<p>It should be noted that Cibola county was split from Valencia county in 1981, and cases in Cibola have been counted to Valencia in the data.</p>
<div id="creating-spatial-zones" class="section level3">
<h3 class="hasAnchor"><a href="#creating-spatial-zones" class="anchor"> </a>Creating spatial zones</h3>
<p>The anomalies considered in the <em>scanstatistics</em> package have both a temporal and a spatial component. The spatial component, called a zone, consists of one or more locations grouped together according to their similarity across features. In this example, the locations are the counties of New Mexico and the features are the coordinates of the county seats. These are made available in the data table <code>NM_geo</code>. Similarity will be measured using the geographical distance between the seats of the counties, taking into account the curvature of the earth. A distance matrix is calculated using the <code>spDists</code> function from the <em>sp</em> package, which is then passed to <code>dist_to_knn</code> (with <em>k</em> = 15 neighbors) and on to <code>knn_zones</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(sp)
<span class="kw">library</span>(magrittr)

<span class="kw">data</span>(NM_geo)

zones &lt;-<span class="st"> </span>NM_geo[, <span class="kw">c</span>(<span class="st">"long"</span>, <span class="st">"lat"</span>), with =<span class="st"> </span><span class="ot">FALSE</span>] %&gt;%
<span class="st">  </span>as.matrix %&gt;%
<span class="st">  </span><span class="kw">spDists</span>(<span class="dt">x =</span> ., <span class="dt">y =</span> ., <span class="dt">longlat =</span> <span class="ot">TRUE</span>) %&gt;%
<span class="st">  </span><span class="kw"><a href="reference/dist_to_knn.html">dist_to_knn</a></span>(<span class="dt">k =</span> <span class="dv">15</span>) %&gt;%
<span class="st">  </span>knn_zones</code></pre></div>
</div>
<div id="a-scan-statistic-for-poisson-data" class="section level3">
<h3 class="hasAnchor"><a href="#a-scan-statistic-for-poisson-data" class="anchor"> </a>A scan statistic for Poisson data</h3>
<p>The Poisson distribution is a natural first option when dealing with (practically) unbounded count data. The <em>scanstatistics</em> package provides the function <code>scan_poisson</code>, which is an expectation-based<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> scan statistic for univariate Poisson-distributed data proposed by <span class="citation">Neill et al. (2005)</span>.</p>
<div id="theoretical-motivation" class="section level4">
<h4 class="hasAnchor"><a href="#theoretical-motivation" class="anchor"> </a>Theoretical motivation</h4>
<p>For the expectation-based Poisson scan statistic, the null hypothesis of no anomaly states that at each location <em>i</em> and duration <em>t</em>, the observed count is Poisson-distributed with expected value &mu;<sub><em>it</em></sub>:</p>
<div class="figure">
<img src="http://quicklatex.com/cache3/4f/ql_f1cf1f5f0b5e44e9eb151e3ee945354f_l3.png" alt="PoissonH0"><p class="caption">PoissonH0</p>
</div>
<p>for locations <em>i</em> = 1,&hellip;,<em>m</em> and durations <em>t</em> = 1,&hellip;,<em>T</em>, with <em>T</em> being the maximum duration considered. Under the alternative hypothesis, there is a space-time cluster <em>W</em> consisting of a spatial zone <em>Z</em> &sub;{1,&hellip;,<em>m</em>} and a time window <em>D</em> = {1,2,&hellip;,d} &sube; {1,2,&hellip;,<em>T</em>} such that the counts in <em>W</em> have their expected values inflated by a factor <em>q</em><sub><em>W</em></sub> &gt; 1 compared to the null hypothesis:</p>
<div class="figure">
<img src="http://quicklatex.com/cache3/ef/ql_b57728d8c880c61acf8037be2baa02ef_l3.png" alt="PoissonH1"><p class="caption">PoissonH1</p>
</div>
<p>For locations and durations outside of this window, counts are assumed to be distributed as under the null hypothesis. Calculating the scan statistic then involves three steps:</p>
<ul><li>For each space-time window <em>W</em>, find the maximum likelihood estimate of <em>q</em><sub><em>W</em></sub>, treating all &mu;<sub><em>it</em></sub>&rsquo;s as constants.</li>
<li>Plug the estimated <em>q</em><sub><em>W</em></sub> into (the logarithm of) a likelihood ratio with the likelihood of the alternative hypothesis in the numerator and the likelihood under the null hypothesis (in which <em>q</em><sub><em>W</em></sub> = 1) in the denominator, again for each <em>W</em>.</li>
<li>Take the scan statistic as the maximum of these likelihood ratios, and the corresponding window <em>W</em><sup>*</sup> as the most likely cluster (MLC).</li>
</ul></div>
<div id="using-the-poisson-scan-statistic" class="section level4">
<h4 class="hasAnchor"><a href="#using-the-poisson-scan-statistic" class="anchor"> </a>Using the Poisson scan statistic</h4>
<p>The first argument to <code>scan_poisson</code> should be a <strong>data table</strong> with columns &lsquo;location&rsquo;, &lsquo;duration&rsquo;, &lsquo;count&rsquo; and &lsquo;mu&rsquo;. The latter two columns contain the observed counts and the estimated Poisson expected value parameters respectively, and the table holds data for the period in which we want to detect anomalies. Locations should be encoded as the integers 1, 2, &hellip;, which means that factor variables can be used for this purpose. The duration column counts time backwards, so that a duration of 1 is the most recent time interval, duration 2 is the second most recent, and so on.</p>
<p>We will create such a table by subsetting the <code>NM_popcas</code> table, which holds the population and the number of brain cancer cases for each year between 1973-1991 and each county of New Mexico. Note that the population numbers are (perhaps poorly) interpolated from the censuses conducted in 1973, 1982, and 1991.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(NM_popcas)

tab &lt;-<span class="st"> </span>NM_popcas[year &gt;=<span class="st"> </span><span class="dv">1986</span> &amp;<span class="st"> </span>year &lt;<span class="st"> </span><span class="dv">1990</span>, ]
tab[, duration :<span class="er">=</span><span class="st"> </span><span class="kw">max</span>(year) -<span class="st"> </span>year +<span class="st"> </span><span class="dv">1</span>]
<span class="co">#&gt;      year     county population count duration</span>
<span class="co">#&gt;   1: 1986 bernalillo 463557.621    27        4</span>
<span class="co">#&gt;   2: 1987 bernalillo 470255.493    17        3</span>
<span class="co">#&gt;   3: 1988 bernalillo 476624.352    26        2</span>
<span class="co">#&gt;   4: 1989 bernalillo 482664.199    34        1</span>
<span class="co">#&gt;   5: 1986     catron   2647.822     1        4</span>
<span class="co">#&gt;  ---                                          </span>
<span class="co">#&gt; 124: 1989      union   4394.518     0        1</span>
<span class="co">#&gt; 125: 1986   valencia  66162.692     2        4</span>
<span class="co">#&gt; 126: 1987   valencia  67267.249     7        3</span>
<span class="co">#&gt; 127: 1988   valencia  68258.359     3        2</span>
<span class="co">#&gt; 128: 1989   valencia  69136.024     5        1</span>
tab[, location :<span class="er">=</span><span class="st"> </span>county]
<span class="co">#&gt;      year     county population count duration   location</span>
<span class="co">#&gt;   1: 1986 bernalillo 463557.621    27        4 bernalillo</span>
<span class="co">#&gt;   2: 1987 bernalillo 470255.493    17        3 bernalillo</span>
<span class="co">#&gt;   3: 1988 bernalillo 476624.352    26        2 bernalillo</span>
<span class="co">#&gt;   4: 1989 bernalillo 482664.199    34        1 bernalillo</span>
<span class="co">#&gt;   5: 1986     catron   2647.822     1        4     catron</span>
<span class="co">#&gt;  ---                                                     </span>
<span class="co">#&gt; 124: 1989      union   4394.518     0        1      union</span>
<span class="co">#&gt; 125: 1986   valencia  66162.692     2        4   valencia</span>
<span class="co">#&gt; 126: 1987   valencia  67267.249     7        3   valencia</span>
<span class="co">#&gt; 127: 1988   valencia  68258.359     3        2   valencia</span>
<span class="co">#&gt; 128: 1989   valencia  69136.024     5        1   valencia</span></code></pre></div>
<p>We still need to add the column &lsquo;mu&rsquo;, which should hold the predicted Poisson expected value parameter &mu;<sub><em>it</em></sub> for each location <em>i</em> and time interval <em>t</em>. In this example we would like to detect a potential cluster of brain cancer in the counties of New Mexico during the years 1986-1989. Thus, we will use data from the years prior to 1986 to estimate the Poisson parameter for all counties in the years following. A simple generalized linear model (GLM) with a linear time trend and an offset for county population size will suffice to demonstrate the scan statistic. We fit such a model and create the needed column as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod_poisson &lt;-<span class="st"> </span><span class="kw">glm</span>(count ~<span class="st"> </span><span class="kw">offset</span>(<span class="kw">log</span>(population)) +<span class="st"> </span><span class="dv">1</span> +<span class="st"> </span><span class="kw">I</span>(year -<span class="st"> </span><span class="dv">1985</span>), 
                   <span class="dt">data =</span> NM_popcas[year &lt;<span class="st"> </span><span class="dv">1986</span>, ], 
                   <span class="dt">family =</span> <span class="kw">poisson</span>(<span class="dt">link =</span> <span class="st">"log"</span>))

<span class="co"># Add the expected value parameter column</span>
tab[, mu :<span class="er">=</span><span class="st"> </span><span class="kw">predict</span>(mod_poisson, tab, <span class="dt">type =</span> <span class="st">"response"</span>)]
<span class="co">#&gt;      year     county population count duration   location         mu</span>
<span class="co">#&gt;   1: 1986 bernalillo 463557.621    27        4 bernalillo 21.0264235</span>
<span class="co">#&gt;   2: 1987 bernalillo 470255.493    17        3 bernalillo 21.5392570</span>
<span class="co">#&gt;   3: 1988 bernalillo 476624.352    26        2 bernalillo 22.0449049</span>
<span class="co">#&gt;   4: 1989 bernalillo 482664.199    34        1 bernalillo 22.5430278</span>
<span class="co">#&gt;   5: 1986     catron   2647.822     1        4     catron  0.1201021</span>
<span class="co">#&gt;  ---                                                                </span>
<span class="co">#&gt; 124: 1989      union   4394.518     0        1      union  0.2052477</span>
<span class="co">#&gt; 125: 1986   valencia  66162.692     2        4   valencia  3.0010612</span>
<span class="co">#&gt; 126: 1987   valencia  67267.249     7        3   valencia  3.0810625</span>
<span class="co">#&gt; 127: 1988   valencia  68258.359     3        2   valencia  3.1570964</span>
<span class="co">#&gt; 128: 1989   valencia  69136.024     5        1   valencia  3.2290261</span></code></pre></div>
<p>We can now calculate the Poisson scan statistic. To give us more confidence in our detection results, we will perform 99 Monte Carlo replications, by which data is generated using the parameters from the null hypothesis and a new scan statistic calculated. This is then summarized in a <em>p</em>-value, calculated as the proportion of times the replicated scan statistics exceeded the observed one. The output of <code>scan_poisson</code> is an object of class &ldquo;scanstatistic&rdquo;, which comes with the print method seen below.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1</span>)
poisson_result &lt;-<span class="st"> </span><span class="kw"><a href="reference/scan_poisson.html">scan_poisson</a></span>(tab, zones, <span class="dt">n_mcsim =</span> <span class="dv">99</span>)
<span class="kw">print</span>(poisson_result)
<span class="co">#&gt; Data distribution:                Poisson</span>
<span class="co">#&gt; Type of scan statistic:           Expectation-based</span>
<span class="co">#&gt; Number of locations considered:   32</span>
<span class="co">#&gt; Maximum duration considered:      4</span>
<span class="co">#&gt; Number of spatial zones:          415</span>
<span class="co">#&gt; Number of Monte Carlo replicates: 99</span>
<span class="co">#&gt; p-value of observed statistic:    0.01</span>
<span class="co">#&gt; Most likely event duration:       4</span>
<span class="co">#&gt; ID of locations in most likely cluster: 15, 26</span></code></pre></div>
<p>As we can see, the most likely cluster for an anomaly stretches from 1986-1989 and involves the locations numbered 15 and 26, which correspond to the counties</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">counties &lt;-<span class="st"> </span><span class="kw">as.character</span>(NM_geo$county)
counties[<span class="kw">c</span>(<span class="dv">15</span>, <span class="dv">26</span>)]
[<span class="dv">1</span>] <span class="st">"losalamos"</span> <span class="st">"santafe"</span>  </code></pre></div>
<p>These are the same counties detected by <span class="citation">Kulldorff et al. (1998)</span>, though their analysis was retrospective rather than prospective as ours was. Ours was also data dredging (adjective) as we used the same study period with hopes of detecting the same cluster.</p>
</div>
<div id="a-heuristic-score-for-locations" class="section level4">
<h4 class="hasAnchor"><a href="#a-heuristic-score-for-locations" class="anchor"> </a>A heuristic score for locations</h4>
<p>We can score each county according to how likely it is to be part of a cluster in a heuristic fashion using the function <code>score_locations</code>, and visualize the results on a heatmap as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Calculate scores and add column with county names</span>
county_scores &lt;-<span class="st"> </span><span class="kw"><a href="reference/score_locations.html">score_locations</a></span>(poisson_result)
county_scores[, county :<span class="er">=</span><span class="st"> </span>counties]
<span class="co">#&gt;     location total_score n_zones    score relative_score     county</span>
<span class="co">#&gt;  1:        1   30062.410     139 54.06908      0.9512967 bernalillo</span>
<span class="co">#&gt;  2:        2   12337.993      59 52.27963      0.9198129     catron</span>
<span class="co">#&gt;  3:        3   22247.553     106 52.47064      0.9231736     chaves</span>
<span class="co">#&gt;  4:        4   15020.282      71 52.88832      0.9305222     colfax</span>
<span class="co">#&gt;  5:        5   18070.368      86 52.53014      0.9242204      curry</span>
<span class="co">#&gt;  6:        6   25488.059     123 51.80500      0.9114621     debaca</span>
<span class="co">#&gt;  7:        7   17942.878      90 49.84133      0.8769132    donaana</span>
<span class="co">#&gt;  8:        8   14521.233      70 51.86155      0.9124571       eddy</span>
<span class="co">#&gt;  9:        9   13619.132      73 46.64086      0.8206039      grant</span>
<span class="co">#&gt; 10:       10   32627.423     151 54.01891      0.9504140  guadalupe</span>
<span class="co">#&gt; 11:       11   23845.890     118 50.52095      0.8888706    harding</span>
<span class="co">#&gt; 12:       12    9134.199      49 46.60305      0.8199387    hidalgo</span>
<span class="co">#&gt; 13:       13   12943.823      64 50.56181      0.8895894        lea</span>
<span class="co">#&gt; 14:       14   28234.269     133 53.07193      0.9337528    lincoln</span>
<span class="co">#&gt; 15:       15   27404.101     136 50.37519      0.8863059  losalamos</span>
<span class="co">#&gt; 16:       16   12495.749      67 46.62593      0.8203411       luna</span>
<span class="co">#&gt; 17:       17    9849.241      48 51.29813      0.9025443   mckinley</span>
<span class="co">#&gt; 18:       18   30446.881     151 50.40874      0.8868963       mora</span>
<span class="co">#&gt; 19:       19   20494.649     102 50.23198      0.8837864      otero</span>
<span class="co">#&gt; 20:       20   22045.224     109 50.56244      0.8896005       quay</span>
<span class="co">#&gt; 21:       21   16585.640      80 51.83012      0.9119042  rioarriba</span>
<span class="co">#&gt; 22:       22   18028.939      88 51.21858      0.9011446  roosevelt</span>
<span class="co">#&gt; 23:       23   29277.047     139 52.65656      0.9264446   sandoval</span>
<span class="co">#&gt; 24:       24    8184.259      44 46.50147      0.8181513    sanjuan</span>
<span class="co">#&gt; 25:       25   34391.659     166 51.79467      0.9112804  sanmiguel</span>
<span class="co">#&gt; 26:       26   31509.455     155 50.82170      0.8941619    santafe</span>
<span class="co">#&gt; 27:       27   19901.759     102 48.77882      0.8582193     sierra</span>
<span class="co">#&gt; 28:       28   27013.809     128 52.76135      0.9282882    socorro</span>
<span class="co">#&gt; 29:       29   24312.210     124 49.01655      0.8624020       taos</span>
<span class="co">#&gt; 30:       30   36148.488     159 56.83725      1.0000000   torrance</span>
<span class="co">#&gt; 31:       31   10969.071      57 48.10996      0.8464513      union</span>
<span class="co">#&gt; 32:       32   28141.949     133 52.89840      0.9306996   valencia</span>
<span class="co">#&gt;     location total_score n_zones    score relative_score     county</span>

<span class="co"># Create a table for plotting</span>
score_map_df &lt;-<span class="st"> </span><span class="kw">merge</span>(NM_map, county_scores, <span class="dt">by =</span> <span class="st">"county"</span>, <span class="dt">all.x =</span> <span class="ot">TRUE</span>)
score_map_df[subregion ==<span class="st"> "cibola"</span>, 
             relative_score :<span class="er">=</span><span class="st"> </span>county_scores[county ==<span class="st"> "valencia"</span>, relative_score]]
<span class="co">#&gt;          county      long      lat group order     region  subregion</span>
<span class="co">#&gt;   1: bernalillo -106.2436 35.21972     1     1 new mexico bernalillo</span>
<span class="co">#&gt;   2: bernalillo -106.2436 35.02491     1     2 new mexico bernalillo</span>
<span class="co">#&gt;   3: bernalillo -106.2436 35.02491     1     3 new mexico bernalillo</span>
<span class="co">#&gt;   4: bernalillo -106.2436 34.95043     1     4 new mexico bernalillo</span>
<span class="co">#&gt;   5: bernalillo -106.1462 34.95043     1     5 new mexico bernalillo</span>
<span class="co">#&gt;  ---                                                                </span>
<span class="co">#&gt; 863:   valencia -106.4097 34.51498    33   895 new mexico   valencia</span>
<span class="co">#&gt; 864:   valencia -106.4212 34.41185    33   896 new mexico   valencia</span>
<span class="co">#&gt; 865:   valencia -106.4498 34.41185    33   897 new mexico   valencia</span>
<span class="co">#&gt; 866:   valencia -106.7592 34.57227    33   898 new mexico   valencia</span>
<span class="co">#&gt; 867:   valencia -107.2061 34.57227    33   899 new mexico   valencia</span>
<span class="co">#&gt;      location total_score n_zones    score relative_score</span>
<span class="co">#&gt;   1:        1    30062.41     139 54.06908      0.9512967</span>
<span class="co">#&gt;   2:        1    30062.41     139 54.06908      0.9512967</span>
<span class="co">#&gt;   3:        1    30062.41     139 54.06908      0.9512967</span>
<span class="co">#&gt;   4:        1    30062.41     139 54.06908      0.9512967</span>
<span class="co">#&gt;   5:        1    30062.41     139 54.06908      0.9512967</span>
<span class="co">#&gt;  ---                                                     </span>
<span class="co">#&gt; 863:       32    28141.95     133 52.89840      0.9306996</span>
<span class="co">#&gt; 864:       32    28141.95     133 52.89840      0.9306996</span>
<span class="co">#&gt; 865:       32    28141.95     133 52.89840      0.9306996</span>
<span class="co">#&gt; 866:       32    28141.95     133 52.89840      0.9306996</span>
<span class="co">#&gt; 867:       32    28141.95     133 52.89840      0.9306996</span>

<span class="kw">ggplot</span>() +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_polygon</span>(<span class="dt">data =</span> score_map_df,
               <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> long, <span class="dt">y =</span> lat, <span class="dt">group =</span> group, 
                             <span class="dt">fill =</span> relative_score),
               <span class="dt">color =</span> <span class="st">"grey"</span>) +
<span class="st">  </span><span class="kw">scale_fill_gradient</span>(<span class="dt">low =</span> <span class="st">"#e5f5f9"</span>, <span class="dt">high =</span> <span class="st">"darkgreen"</span>,
                      <span class="dt">guide =</span> <span class="kw">guide_colorbar</span>(<span class="dt">title =</span> <span class="st">"Relative</span><span class="ch">\n</span><span class="st">Score"</span>)) +
<span class="st">  </span><span class="kw">geom_text</span>(<span class="dt">data =</span> centroids, 
            <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> long, <span class="dt">y =</span> lat, <span class="dt">label =</span> subregion),
            <span class="dt">alpha =</span> <span class="fl">0.5</span>) +
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">"County scores"</span>)</code></pre></div>
<p><img src="README_figures/unnamed-chunk-8-1.png" width="960"></p>
<p>As we can see, this does not match up entirely with the previous results as Torrance was not part of the most likely cluster.</p>
</div>
<div id="finding-the-top-scoring-clusters" class="section level4">
<h4 class="hasAnchor"><a href="#finding-the-top-scoring-clusters" class="anchor"> </a>Finding the top-scoring clusters</h4>
<p>Finally, if we want to know not just the most likely cluster, but say the five top-scoring space-time clusters, we can use the function <code>top_clusters</code>. The clusters returned can either be overlapping or non-overlapping in the spatial dimension, according to our liking.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">top5 &lt;-<span class="st"> </span><span class="kw"><a href="reference/top_clusters.html">top_clusters</a></span>(poisson_result, <span class="dt">k =</span> <span class="dv">5</span>, <span class="dt">overlapping =</span> <span class="ot">FALSE</span>)

<span class="co"># Find the counties corresponding to the spatial zones of the 5 clusters.</span>
top_counties &lt;-<span class="st"> </span>top5$zone %&gt;%
<span class="st">  </span>purrr::<span class="kw">map</span>(get_zone, <span class="dt">zones =</span> zones) %&gt;%
<span class="st">  </span>purrr::<span class="kw">map</span>(function(x) counties[x])

<span class="co"># Add the counties corresponding to the zones as a column</span>
top5[, counties :<span class="er">=</span><span class="st"> </span>top_counties]
<span class="co">#&gt;    zone duration statistic</span>
<span class="co">#&gt; 1:   49        4 9.1806711</span>
<span class="co">#&gt; 2:    3        2 6.8196550</span>
<span class="co">#&gt; 3:  140        4 3.5377879</span>
<span class="co">#&gt; 4:   10        4 3.4072029</span>
<span class="co">#&gt; 5:    9        2 0.8372729</span>
<span class="co">#&gt;                                               counties</span>
<span class="co">#&gt; 1:                                   losalamos,santafe</span>
<span class="co">#&gt; 2:                                              chaves</span>
<span class="co">#&gt; 3: bernalillo,lincoln,sierra,socorro,torrance,valencia</span>
<span class="co">#&gt; 4:                                           guadalupe</span>
<span class="co">#&gt; 5:                                               grant</span></code></pre></div>
<p>To get <em>p</em>-values for these clusters, the values of the cluster-specific statistics in the table above can be compared to the replicate scan statistics calculated earlier. These <em>p</em>-values will be conservative, since secondary clusters from the original data are compared to the most likely clusters from the replicate data sets.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">top5[, pvalue :<span class="er">=</span><span class="st"> </span><span class="kw"><a href="reference/mc_pvalue.html">mc_pvalue</a></span>(statistic, poisson_result$replicated)]
<span class="co">#&gt;    zone duration statistic</span>
<span class="co">#&gt; 1:   49        4 9.1806711</span>
<span class="co">#&gt; 2:    3        2 6.8196550</span>
<span class="co">#&gt; 3:  140        4 3.5377879</span>
<span class="co">#&gt; 4:   10        4 3.4072029</span>
<span class="co">#&gt; 5:    9        2 0.8372729</span>
<span class="co">#&gt;                                               counties pvalue</span>
<span class="co">#&gt; 1:                                   losalamos,santafe   0.01</span>
<span class="co">#&gt; 2:                                              chaves   0.01</span>
<span class="co">#&gt; 3: bernalillo,lincoln,sierra,socorro,torrance,valencia   0.48</span>
<span class="co">#&gt; 4:                                           guadalupe   0.50</span>
<span class="co">#&gt; 5:                                               grant   1.00</span>

top5
<span class="co">#&gt;    zone duration statistic</span>
<span class="co">#&gt; 1:   49        4 9.1806711</span>
<span class="co">#&gt; 2:    3        2 6.8196550</span>
<span class="co">#&gt; 3:  140        4 3.5377879</span>
<span class="co">#&gt; 4:   10        4 3.4072029</span>
<span class="co">#&gt; 5:    9        2 0.8372729</span>
<span class="co">#&gt;                                               counties pvalue</span>
<span class="co">#&gt; 1:                                   losalamos,santafe   0.01</span>
<span class="co">#&gt; 2:                                              chaves   0.01</span>
<span class="co">#&gt; 3: bernalillo,lincoln,sierra,socorro,torrance,valencia   0.48</span>
<span class="co">#&gt; 4:                                           guadalupe   0.50</span>
<span class="co">#&gt; 5:                                               grant   1.00</span></code></pre></div>
</div>
</div>
<div id="a-scan-statistic-for-negative-binomial-data" class="section level3">
<h3 class="hasAnchor"><a href="#a-scan-statistic-for-negative-binomial-data" class="anchor"> </a>A scan statistic for negative binomial data</h3>
<p>For count data with overdispersion, the <em>scanstatistics</em> package provides the function <code>scan_negbin</code>, which is the expectation-based scan statistic invented by <span class="citation">Tango, Takahashi, and Kohriyama (2011)</span>. This scan statistic assumes that the data follows a negative binomial distribution parametrized by its expected value &mu; and a parameter &theta; such that a count <em>Y</em> has variance Var(<em>Y</em>) = &mu; + &mu;<sup>2</sup> / &theta;. The parameters &mu; and &theta; may vary over both location and time.</p>
<div id="theoretical-motivation-1" class="section level4">
<h4 class="hasAnchor"><a href="#theoretical-motivation-1" class="anchor"> </a>Theoretical motivation</h4>
<p>The negative binomial scan statistic comes in two versions, each with a different assumption of how an anomaly with manifest in the data. The first version makes the same assumption as the Poisson scan statistic in the previous section: an anomaly that occurs in a space-time window <em>W</em> will have the effect of increasing the expected value of the counts in that window by a factor <em>q</em><sub><em>W</em></sub> &gt; 1 in comparison to what was predicted. This factor <em>q</em><sub><em>W</em></sub> is the same for all locations in <em>W</em> and constant over time. In the second version of the scan statistic, the factor <em>q</em><sub><em>W</em></sub> increases monotonically over time. The null and alternative hypotheses are otherwise as for the Poisson scan statistic, except that the negative binomial distribution is used instead. Further, the scan statistic is calculated using the score and Fisher information rather than a likelihood ratio.</p>
</div>
<div id="using-the-negative-binomial-scan-statistic" class="section level4">
<h4 class="hasAnchor"><a href="#using-the-negative-binomial-scan-statistic" class="anchor"> </a>Using the negative binomial scan statistic</h4>
<p>Similar to <code>scan_poisson</code>, the first argument to <code>scan_negbin</code> should be a <strong>data table</strong> with columns &lsquo;location&rsquo;, &lsquo;duration&rsquo;, &lsquo;count&rsquo;, &lsquo;mu&rsquo; and &lsquo;theta&rsquo;. The second and third arguments specify the spatial zones and the number of Monte Carlo replications respectively. The fourth argument specifies the alternative hypothesis; the choices are <code>version = "ordinary"</code> (default) and <code>version = "increasing"</code>, with the implications described above.</p>
<p>To demonstrate the negative binomial scan statistic, we fit a negative binomial GLM to the data. It should be noted that this is purely for demonstrational purposes: the negative binomial distribution does not fit this data well at all. So if you happen to know of a dataset more suitable, please let me know!</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">suppressWarnings</span>(
mod_negbin &lt;-<span class="st"> </span>MASS::<span class="kw">glm.nb</span>(count ~<span class="st"> </span><span class="kw">offset</span>(<span class="kw">log</span>(population)) +<span class="st"> </span><span class="dv">1</span> +<span class="st"> </span><span class="kw">I</span>(year -<span class="st"> </span><span class="dv">1985</span>), 
                         <span class="dt">data =</span> NM_popcas[year &lt;<span class="st"> </span><span class="dv">1986</span>, ],
                         <span class="dt">link =</span> log)
)

<span class="co"># Add the parameters as columns</span>
tab[, mu :<span class="er">=</span><span class="st"> </span><span class="kw">predict</span>(mod_negbin, tab, <span class="dt">type =</span> <span class="st">"response"</span>)]
<span class="co">#&gt;      year     county population count duration   location         mu</span>
<span class="co">#&gt;   1: 1986 bernalillo 463557.621    27        4 bernalillo 21.0236771</span>
<span class="co">#&gt;   2: 1987 bernalillo 470255.493    17        3 bernalillo 21.5362286</span>
<span class="co">#&gt;   3: 1988 bernalillo 476624.352    26        2 bernalillo 22.0415853</span>
<span class="co">#&gt;   4: 1989 bernalillo 482664.199    34        1 bernalillo 22.5394082</span>
<span class="co">#&gt;   5: 1986     catron   2647.822     1        4     catron  0.1200864</span>
<span class="co">#&gt;  ---                                                                </span>
<span class="co">#&gt; 124: 1989      union   4394.518     0        1      union  0.2052148</span>
<span class="co">#&gt; 125: 1986   valencia  66162.692     2        4   valencia  3.0006692</span>
<span class="co">#&gt; 126: 1987   valencia  67267.249     7        3   valencia  3.0806293</span>
<span class="co">#&gt; 127: 1988   valencia  68258.359     3        2   valencia  3.1566210</span>
<span class="co">#&gt; 128: 1989   valencia  69136.024     5        1   valencia  3.2285077</span>
tab[, theta :<span class="er">=</span><span class="st"> </span>mod_negbin$theta]
<span class="co">#&gt;      year     county population count duration   location         mu</span>
<span class="co">#&gt;   1: 1986 bernalillo 463557.621    27        4 bernalillo 21.0236771</span>
<span class="co">#&gt;   2: 1987 bernalillo 470255.493    17        3 bernalillo 21.5362286</span>
<span class="co">#&gt;   3: 1988 bernalillo 476624.352    26        2 bernalillo 22.0415853</span>
<span class="co">#&gt;   4: 1989 bernalillo 482664.199    34        1 bernalillo 22.5394082</span>
<span class="co">#&gt;   5: 1986     catron   2647.822     1        4     catron  0.1200864</span>
<span class="co">#&gt;  ---                                                                </span>
<span class="co">#&gt; 124: 1989      union   4394.518     0        1      union  0.2052148</span>
<span class="co">#&gt; 125: 1986   valencia  66162.692     2        4   valencia  3.0006692</span>
<span class="co">#&gt; 126: 1987   valencia  67267.249     7        3   valencia  3.0806293</span>
<span class="co">#&gt; 127: 1988   valencia  68258.359     3        2   valencia  3.1566210</span>
<span class="co">#&gt; 128: 1989   valencia  69136.024     5        1   valencia  3.2285077</span>
<span class="co">#&gt;         theta</span>
<span class="co">#&gt;   1: 8703.761</span>
<span class="co">#&gt;   2: 8703.761</span>
<span class="co">#&gt;   3: 8703.761</span>
<span class="co">#&gt;   4: 8703.761</span>
<span class="co">#&gt;   5: 8703.761</span>
<span class="co">#&gt;  ---         </span>
<span class="co">#&gt; 124: 8703.761</span>
<span class="co">#&gt; 125: 8703.761</span>
<span class="co">#&gt; 126: 8703.761</span>
<span class="co">#&gt; 127: 8703.761</span>
<span class="co">#&gt; 128: 8703.761</span></code></pre></div>
<p>We can now use <code>scan_negbin</code> to find the most likely cluster using the ordinary version of the scan statistic, again making 99 Monte Carlo replications to obtain a <em>p</em>-value:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1</span>)
negbin_result1 &lt;-<span class="st"> </span><span class="kw"><a href="reference/scan_negbin.html">scan_negbin</a></span>(tab, zones, <span class="dt">n_mcsim =</span> <span class="dv">99</span>, <span class="dt">version =</span> <span class="st">"ordinary"</span>)
<span class="kw">print</span>(negbin_result1)
<span class="co">#&gt; Data distribution:                negative binomial</span>
<span class="co">#&gt; Type of scan statistic:           expectation-based</span>
<span class="co">#&gt; Number of locations considered:   32</span>
<span class="co">#&gt; Maximum duration considered:      4</span>
<span class="co">#&gt; Number of spatial zones:          415</span>
<span class="co">#&gt; Number of Monte Carlo replicates: 99</span>
<span class="co">#&gt; p-value of observed statistic:    0.07</span>
<span class="co">#&gt; Most likely event duration:       4</span>
<span class="co">#&gt; ID of locations in most likely cluster: 15, 26</span></code></pre></div>
<p>The ordinary version of the negative binomial scan statistic evidently finds the same cluster as the Poisson scan statistic. The increasing version does not, however:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1</span>)
negbin_result2 &lt;-<span class="st"> </span><span class="kw"><a href="reference/scan_negbin.html">scan_negbin</a></span>(tab, zones, <span class="dt">n_mcsim =</span> <span class="dv">99</span>, <span class="dt">version =</span> <span class="st">"increasing"</span>)
<span class="kw">print</span>(negbin_result2)
<span class="co">#&gt; Data distribution:                negative binomial</span>
<span class="co">#&gt; Type of scan statistic:           expectation-based</span>
<span class="co">#&gt; Number of locations considered:   32</span>
<span class="co">#&gt; Maximum duration considered:      4</span>
<span class="co">#&gt; Number of spatial zones:          415</span>
<span class="co">#&gt; Number of Monte Carlo replicates: 99</span>
<span class="co">#&gt; p-value of observed statistic:    0.04</span>
<span class="co">#&gt; Most likely event duration:       2</span>
<span class="co">#&gt; ID of locations in most likely cluster: 3</span></code></pre></div>
<p>The cluster found here consists of Chaves county in the years 1988-1989, which was one of the secondary clusters found by <span class="citation">Kulldorff et al. (1998)</span>. The results from the two negative binomial scans above could be further explored using the functions <code>score_locations</code> and <code>top_clusters</code>, just as for the Poisson scan statistic. Since these functions have already been demonstrated, we move on to a scan statistic for data with an excess of zeros.</p>
</div>
</div>
<div id="a-scan-statistic-for-zero-inflated-poisson-data" class="section level3">
<h3 class="hasAnchor"><a href="#a-scan-statistic-for-zero-inflated-poisson-data" class="anchor"> </a>A scan statistic for zero-inflated Poisson data</h3>
<p>For zero-inflated count data, the <em>scanstatistics</em> package provides the function <code>scan_zip</code>, which an expectation-based scan statistic for zero-inflated Poisson (ZIP) data devised by <span class="citation">Kjellson (2015)</span>. The ZIP distribution is parametrized by the expected value &mu; of the Poisson component and the probability <em>p</em> of a structural zero.</p>
<div id="theoretical-motivation-2" class="section level4">
<h4 class="hasAnchor"><a href="#theoretical-motivation-2" class="anchor"> </a>Theoretical motivation</h4>
<p>The ZIP scan statistic makes a similar assumtion regarding outbreaks as the Poisson scan statistic does: an anomaly that occurs in a space-time window <em>W</em> will have the effect of increasing the Poisson expected value parameter of the counts in that window by a factor <em>q</em><sub><em>W</em></sub> &gt;1 in comparison to what was predicted. This factor <em>q</em><sub><em>W</em></sub> is the same for all locations in <em>W</em> and constant over the duration of the anomaly. For all windows <em>W</em> considered, <em>q</em><sub><em>W</em></sub> is estimated using the EM algorithm and a likelihood ratio statistic is computed. The scan statistic is the maximum of these statistics over all windows <em>W</em>.</p>
</div>
<div id="using-the-zip-scan-statistic" class="section level4">
<h4 class="hasAnchor"><a href="#using-the-zip-scan-statistic" class="anchor"> </a>Using the ZIP scan statistic</h4>
<p>Similar to <code>scan_poisson</code>, the first argument to <code>scan_zip</code> should be a <strong>data table</strong> with columns &lsquo;location&rsquo;, &lsquo;duration&rsquo;, &lsquo;count&rsquo;, &lsquo;mu&rsquo; and &lsquo;p&rsquo;. The second and third arguments specify the spatial zones and the number of Monte Carlo replications respectively.</p>
<p>To demonstrate the ZIP scan statistic, we fit a zero-inflated Poisson regression model to the data. Just as for the negative binomial distribution, it should be noted that this is purely for demonstrational purposes: there are probably more suitable datasets out there, and if you happen to know of one, please let me know!</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(pscl, <span class="dt">quietly =</span> <span class="ot">TRUE</span>)
<span class="co">#&gt; Classes and Methods for R developed in the</span>
<span class="co">#&gt; Political Science Computational Laboratory</span>
<span class="co">#&gt; Department of Political Science</span>
<span class="co">#&gt; Stanford University</span>
<span class="co">#&gt; Simon Jackman</span>
<span class="co">#&gt; hurdle and zeroinfl functions by Achim Zeileis</span>
mod_zip &lt;-<span class="st"> </span><span class="kw">zeroinfl</span>(count ~<span class="st"> </span><span class="kw">offset</span>(<span class="kw">log</span>(population)) +<span class="st"> </span><span class="dv">1</span> +<span class="st"> </span><span class="kw">I</span>(year -<span class="st"> </span><span class="dv">1985</span>),
                    <span class="dt">data =</span> NM_popcas[year &lt;<span class="st"> </span><span class="dv">1986</span>, ],
                    <span class="dt">dist =</span> <span class="st">"poisson"</span>, <span class="dt">link =</span> <span class="st">"logit"</span>)

<span class="co"># Add the parameters as columns</span>
tab[, mu :<span class="er">=</span><span class="st"> </span><span class="kw">predict</span>(mod_zip, tab, <span class="dt">type =</span> <span class="st">"count"</span>)]
<span class="co">#&gt;      year     county population count duration   location        mu</span>
<span class="co">#&gt;   1: 1986 bernalillo 463557.621    27        4 bernalillo 21.087867</span>
<span class="co">#&gt;   2: 1987 bernalillo 470255.493    17        3 bernalillo 21.592276</span>
<span class="co">#&gt;   3: 1988 bernalillo 476624.352    26        2 bernalillo 22.089016</span>
<span class="co">#&gt;   4: 1989 bernalillo 482664.199    34        1 bernalillo 22.577759</span>
<span class="co">#&gt;   5: 1986     catron   2647.822     1        4     catron  0.120453</span>
<span class="co">#&gt;  ---                                                               </span>
<span class="co">#&gt; 124: 1989      union   4394.518     0        1      union  0.205564</span>
<span class="co">#&gt; 125: 1986   valencia  66162.692     2        4   valencia  3.009831</span>
<span class="co">#&gt; 126: 1987   valencia  67267.249     7        3   valencia  3.088646</span>
<span class="co">#&gt; 127: 1988   valencia  68258.359     3        2   valencia  3.163414</span>
<span class="co">#&gt; 128: 1989   valencia  69136.024     5        1   valencia  3.234001</span>
<span class="co">#&gt;         theta</span>
<span class="co">#&gt;   1: 8703.761</span>
<span class="co">#&gt;   2: 8703.761</span>
<span class="co">#&gt;   3: 8703.761</span>
<span class="co">#&gt;   4: 8703.761</span>
<span class="co">#&gt;   5: 8703.761</span>
<span class="co">#&gt;  ---         </span>
<span class="co">#&gt; 124: 8703.761</span>
<span class="co">#&gt; 125: 8703.761</span>
<span class="co">#&gt; 126: 8703.761</span>
<span class="co">#&gt; 127: 8703.761</span>
<span class="co">#&gt; 128: 8703.761</span>
tab[, p :<span class="er">=</span><span class="st"> </span><span class="kw">predict</span>(mod_zip, tab, <span class="dt">type =</span> <span class="st">"zero"</span>)]
<span class="co">#&gt;      year     county population count duration   location        mu</span>
<span class="co">#&gt;   1: 1986 bernalillo 463557.621    27        4 bernalillo 21.087867</span>
<span class="co">#&gt;   2: 1987 bernalillo 470255.493    17        3 bernalillo 21.592276</span>
<span class="co">#&gt;   3: 1988 bernalillo 476624.352    26        2 bernalillo 22.089016</span>
<span class="co">#&gt;   4: 1989 bernalillo 482664.199    34        1 bernalillo 22.577759</span>
<span class="co">#&gt;   5: 1986     catron   2647.822     1        4     catron  0.120453</span>
<span class="co">#&gt;  ---                                                               </span>
<span class="co">#&gt; 124: 1989      union   4394.518     0        1      union  0.205564</span>
<span class="co">#&gt; 125: 1986   valencia  66162.692     2        4   valencia  3.009831</span>
<span class="co">#&gt; 126: 1987   valencia  67267.249     7        3   valencia  3.088646</span>
<span class="co">#&gt; 127: 1988   valencia  68258.359     3        2   valencia  3.163414</span>
<span class="co">#&gt; 128: 1989   valencia  69136.024     5        1   valencia  3.234001</span>
<span class="co">#&gt;         theta            p</span>
<span class="co">#&gt;   1: 8703.761 0.0272006762</span>
<span class="co">#&gt;   2: 8703.761 0.0256142640</span>
<span class="co">#&gt;   3: 8703.761 0.0240970736</span>
<span class="co">#&gt;   4: 8703.761 0.0226486148</span>
<span class="co">#&gt;   5: 8703.761 0.0001596879</span>
<span class="co">#&gt;  ---                      </span>
<span class="co">#&gt; 124: 8703.761 0.0002109432</span>
<span class="co">#&gt; 125: 8703.761 0.0039749908</span>
<span class="co">#&gt; 126: 8703.761 0.0037461981</span>
<span class="co">#&gt; 127: 8703.761 0.0035237432</span>
<span class="co">#&gt; 128: 8703.761 0.0033083469</span></code></pre></div>
<p>We can now use <code>scan_zip</code> to find the most likely cluster, again making 99 Monte Carlo replications to obtain a <em>p</em>-value:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1</span>)
zip_result &lt;-<span class="st"> </span><span class="kw"><a href="reference/scan_zip.html">scan_zip</a></span>(tab, zones, <span class="dt">n_mcsim =</span> <span class="dv">99</span>)
<span class="kw">print</span>(zip_result)
<span class="co">#&gt; Data distribution:                zero-inflated Poisson</span>
<span class="co">#&gt; Type of scan statistic:           Expectation-based</span>
<span class="co">#&gt; Number of locations considered:   32</span>
<span class="co">#&gt; Maximum duration considered:      4</span>
<span class="co">#&gt; Number of spatial zones:          415</span>
<span class="co">#&gt; Number of Monte Carlo replicates: 99</span>
<span class="co">#&gt; p-value of observed statistic:    0.01</span>
<span class="co">#&gt; Most likely event duration:       4</span>
<span class="co">#&gt; ID of locations in most likely cluster: 15, 26</span></code></pre></div>
<p>The zero-inflated Poisson statistic finds the same cluster as <span class="citation">Kulldorff et al. (1998)</span>.</p>
</div>
</div>
</div>
</div>
<div id="feedback" class="section level1">
<h1 class="hasAnchor"><a href="#feedback" class="anchor"> </a>Feedback</h1>
<p>If you think this package lacks some functionality, or that something needs better documentation, I happily accept feedback either here at GitHub or via email at <a href="mailto:benjak@math.su.se">benjak@math.su.se</a>. I&rsquo;m also very interested in applying the methods in this package (current and future) to new problems, so if you know of any suitable public datasets, please tell me! A dataset with a multivariate response (e.g.&nbsp;multiple counter variables) would be of particular interest for some of the scan statistics that will appear in future versions of the package.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="hasAnchor"><a href="#references" class="anchor"> </a>References</h1>
<div id="refs" class="references">
<div id="ref-Kjellson2015">
<p>Kjellson, Benjamin. 2015. &ldquo;Spatiotemporal Outbreak Detection: A Scan Statistic Based on the Zero-Inflated Poisson Distribution.&rdquo; Master&rsquo;s thesis, Sweden: Stockholm University, Division of Mathematical Statistics. <a href="https://goo.gl/GdseSh" class="uri">https://goo.gl/GdseSh</a>.</p>
</div>
<div id="ref-rsatscan">
<p>Kleinman, Ken. 2015. <em>Rsatscan: Tools, Classes, and Methods for Interfacing with Satscan Stand-Alone Software</em>. <a href="https://CRAN.R-project.org/package=rsatscan" class="uri">https://CRAN.R-project.org/package=rsatscan</a>.</p>
</div>
<div id="ref-Kulldorff1998">
<p>Kulldorff, Martin, William F. Athas, Eric J. Feuer, Barry A. Miller, and Charles R. Key. 1998. &ldquo;Evaluating Cluster Alarms: A Space-Time Scan Statistic and Brain Cancer in Los Alamos.&rdquo; <em>American Journal of Public Health</em> 88 (9): 1377&ndash;80.</p>
</div>
<div id="ref-Neill2005">
<p>Neill, Daniel B., Andrew W. Moore, Maheshkumar Sabhnani, and Kenny Daniel. 2005. &ldquo;Detection of Emerging Space-Time Clusters.&rdquo; In <em>Proceedings of the Eleventh Acm Sigkdd International Conference on Knowledge Discovery in Data Mining</em>, 218&ndash;27. ACM.</p>
</div>
<div id="ref-Tango2011">
<p>Tango, Toshiro, Kunihiko Takahashi, and Kazuaki Kohriyama. 2011. &ldquo;A Space-Time Scan Statistic for Detecting Emerging Outbreaks.&rdquo; <em>Biometrics</em> 67 (1): 106&ndash;15.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr><ol><li id="fn1"><p>Expectation-based scan statistics use past non-anomalous data to estimate distribution parameters, and then compares observed cluster counts from the time period of interest to these estimates. In contrast, <em>population-based</em> scan statistics compare counts in a cluster tothose outside, only using data from the period of interest.<a href="#fnref1">&#8617;</a></p></li>
</ol></div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Links</h2><ul class="list-unstyled"><li>Download from CRAN at <br><a href="https://cran.r-project.org/package=scanstatistics">https://&#8203;cran.r-project.org/&#8203;package=scanstatistics</a></li>
<li>Browse source code at <br><a href="https://github.com/BenjaK/scanstatistics">https://&#8203;github.com/&#8203;BenjaK/&#8203;scanstatistics</a></li>
<li>Report a bug at <br><a href="https://github.com/BenjaK/scanstatistics/issues">https://&#8203;github.com/&#8203;BenjaK/&#8203;scanstatistics/&#8203;issues</a></li>
</ul><h2>License</h2>
<p>GPL (&gt;= 3)</p>
<h2>Developers</h2><ul class="list-unstyled"><li>Benjamin Kjellson <br><small class="roles"> Author, maintainer </small> </li>
</ul><html><body><h2>Dev status</h2><ul class="list-unstyled"><li><a href="https://travis-ci.org/BenjaK/scanstatistics">
  <img src="https://travis-ci.org/BenjaK/scanstatistics.svg?branch=master" alt="Build Status"></a></li>
<li><a href="https://cran.r-project.org/package=scanstatistics">
  <img src="http://www.r-pkg.org/badges/version/scanstatistics" alt="CRAN_Status_Badge"></a></li>
<li><a href="http://cran.rstudio.com/web/packages/scanstatistics/index.html">
  <img src="https://cranlogs.r-pkg.org/badges/grand-total/scanstatistics" alt="CRAN downloads"></a></li>
</ul></body></html></div>

</div>


      <footer><div class="copyright">
  <p>Developed by Benjamin Kjellson.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer></div>

  </body></html>
